[basic_settings]
project_name=intent_classification
saving_path=./saved
mode=training

[data_loader]
token_path=./model/pretrained_model/ckip-bert-base-chinese/
maxlen=512
batch_size=4
num_workers=0
l1_target_mapping = {'TQ001': 0, 'TQ002': 1, 'TQ003': 2, 'TQ004': 3, 'TQ005': 4}
target_mapping = {'SQ001': 0, 'SQ002': 1, 'SQ003': 2, 'SQ004': 3, 'SQ005': 4, 'SQ007': 5, 'SQ008': 6, 'SQ009': 7, 'SQ010': 8, 'SQ011': 9, 'SQ012': 10, 'SQ013': 11, 'SQ014': 12, 'SQ015': 13, 'SQ016': 14}


[training_dataset_setting]
file_path=./source/dataset/original_data/dialogue_dataset_20230914.csv
split_weight=[1,0,0]

[validation_dataset_setting]
file_path=./source/dataset/original_data/dialogue_valid_dataset_20230914.csv
split_weight=[1,0,0]

[model]
pretrained_model_name_or_path=./model/pretrained_model/ckip-bert-base-chinese/
num_labels=15

[training_config]
device=cuda:0
num_epoch=50
max_norm=1
weight_decay=0.01
metric=['F1score_micro','F1score_macro','Recall_micro','Recall_macro','Precision_macro','Precision_micro', 'Accuray','Roc_auc_ovo','Roc_auc_ovr']
loss='CrossEntropyLoss'
optimizer={'AdamW':{'lr':1e-5}}
lr_scheduler='get_consine_schedule_with_warmup'
monitor=max val_F1score_macro
early_stopping_patience=3
early_stopping_threshold=0.0

[callback]
mlflow=False,
tensorboard=False
earlystopping=True

[log]
is_log=True
evaluation_period=1
save_period=2
save_pretained_name=intent_bert_model